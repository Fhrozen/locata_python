# -*- coding: utf-8 -*-
import numpy as np
import sys
import librosa


def MUSIC(inputs, options):
    """MUSIC

    implementation of Multiple SIgnal Classification (MUSIC) algorithm as described in [3].

    Inputs:
    in:
        in.array:               String containing array name: 'eigenmike', 'dicit', 'dummy', 'benchmark2'
        in.y:                   Data matrix
        in.fs:                  Sampling frequency [Hz]
        in.timestamps:          Vector of timestamps at which DoA estimates must be PROVIDED
        in.time:                6xT matrix of system clock times
        in.array.rotation:      Rotation matrix describing array orientation in 3D for each timestamp
        in.array.mic:           Matrix describing microphone positions for each timestamp
    opts:                     Settings structure generated by init()

    Outputs:
    out:
        out.source:             N x 1 struct array, one element for each N estimated sources. In this function: N = 1
                                (single-source)
        out.source(src_idx).azimuth:      Tx1 vector of azimuth estimates, where T is the number of timestamps
                                          in in.timestamps
        out.source(src_idx).elevation:    Tx1 vector of elevation estimates
        out.source(src_idx).time:         Tx1 vector of system time values of estimates (must be identical to in.time!)
        out.source(src_idx).timestamps:   Tx1 vector of timestamps of estimates (must be identical to in.timestamps!)

    References:
        [1]    J. Benesty, C. Jingdong, and I. Cohen, Design of Circular Differential Microphone Arrays.
               Springer, 2015.
        [2]    I. Cohen, J. Benesty, and S. Gannot, Speech Processing in Modern Communication, vol. 3. Berlin,
               Heidelberg: Springer Science & Business Media, 2009.
        [3]    H. L. Van Trees, Detection, Estimation, and Modulation Theory, Optimum Array Processing. John Wiley
               & Sons, 2004.
    """
    az = np.linspace(-np.pi, np.pi, 73)  # Resolution of azimuth: 5 dg
    el = np.linspace(0, np.pi, 19)  # Resolution of elevation: 10 dg

    if inputs.array_name == 'dicit':
        subarray = np.array([6, 7, 9])
        ref_mic = 1
    elif 'benchmark2':
        subarray = np.arange(12).astype(np.int)
        ref_mic = 1
    elif 'eigenmike':
        subarray = np.arange(32).astype(np.int)
        ref_mic = 1
    elif 'dummy':
        subarray = np.arange(4).astype(np.int)
        ref_mic = 1
    else:
        log.error('Array type {} does not exists'.format(inputs.array_name))
        sys.exit(1)

    # MUSIC
    numMic = subarray.shape[0]

    fftPoint = 1024
    frame_duration = 0.03
    frames_per_block = 100  # Number of frames per block
    block_step = 10

    frame_length = int(frame_duration * inputs.fs)

    # -> OptiTracker sampling rate

    # Unique timestamps:
    opti_timestamps, unique_idx = np.unique(inputs.timestamps, return_index=True)
    opti_rotation = inputs.array.rotation[:, unique_idx]
    opti_mics = inputs.array.mic[:, unique_idx]

    duration = inputs.y.shape[0]
    # -> STFT
    X = np.stack([librosa.stft(inputs.y[:, ch],
                               n_fft=fftPoint,
                               hop_length=frame_length // 4,
                               win_length=fftPoint,
                               window='hamming',
                               pad_mode='reflect') for ch in subarray], axis=1)
    X = X.transpose(2, 0, 1)
    frame_timestamp = librosa.samples_to_time(np.arange(0, duration, frame_length // 4),
                                              sr=inputs.fs)
    fft_freq = librosa.fft_frequencies(sr=inputs.fs, n_fft=fftPoint)

    nframe = frame_timestamp.shape[0]

    # Check that the frame times and Optitracker times intersect:
    opti_timestamps = opti_timestamps[opti_timestamps < frame_timestamp[-1]]

    # -> MUSIC
    # Make blocks out of frames:
    frame_srt = np.arange(0, nframe, block_step)
    frame_end = np.arange(frames_per_block, nframe, block_step)
    frame_end = np.pad(frame_end, (0, frame_srt.shape[0] - frame_end.shape[0]), 'constant', constant_values=nframe - 1)
    nblocks = frame_srt.shape[0]

    block_timestamps = np.mean([frame_timestamp[frame_srt], frame_timestamp[frame_end]], axis=0)
    # Bandlimit signals to avoid spatial aliasing / low freq effects:
    # NOTE: This is crucial for the DICIT array, the other arrays can be
    # evaluated for fullband signals.
    valid_freq_idx = (800 < fft_freq) * (fft_freq < 1400)
    valid_x = X[:, valid_freq_idx]
    # print(valid_x.shape)
    # print(opti_timestamps.shape)
    # print(fft_freq.shape)

    return X
